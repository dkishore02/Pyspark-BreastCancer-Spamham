{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Load relevant objects\n",
    "sc = SparkContext('local')\n",
    "log_txt = sc.textFile(\"spam.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'class,text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_txt = log_txt.filter(lambda line: line != header)\n",
    "\n",
    "temp_var = log_txt.map(lambda k: k.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thatÂ’s th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df=temp_var.toDF(header.split(\",\"))\n",
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'text']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[class: string, text: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|    0|Go until jurong p...|\n",
      "|    0|Ok lar... Joking ...|\n",
      "|    1|Free entry in 2 a...|\n",
      "|    0|U dun say so earl...|\n",
      "|    0|Nah I don't think...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df = log_df.withColumn(log_df.columns[0], when(col(log_df.columns[0]) == \"spam\", 1).otherwise(0))\n",
    "log_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.filter(log_df[log_df.columns[0]] == 1).select(log_df.columns[0]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.40150699677072"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "747/log_df.count() *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see only the spam and ham are present in the dataset. but the dataset is not balanced. so we need to balance the dataset.\n",
    "by using imbalanced-learn library we can do that later but for now we will use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=log_df.columns[1], outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|class|                text|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|Go until jurong p...|[go, until, juron...|\n",
      "|    0|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|    1|Free entry in 2 a...|[free, entry, in,...|\n",
      "|    0|U dun say so earl...|[u, dun, say, so,...|\n",
      "|    0|Nah I don't think...|[nah, i, don't, t...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"words\", outputCol=\"result\")\n",
    "model = word2Vec.fit(wordsData)\n",
    "\n",
    "result = model.transform(wordsData)\n",
    "# for row in tqdm(result.collect()):\n",
    "#     text, vector = row\n",
    "#     print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2Vector(text):\n",
    "    return model.getVectors(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'text', 'words', 'result']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              result|\n",
      "+--------------------+\n",
      "|[2.35824286937713...|\n",
      "|[-0.0904866193110...|\n",
      "|[-0.1330838936846...|\n",
      "|[-0.1861538268964...|\n",
      "|[-0.2342496712047...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('result').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = result.select(log_df.columns[0], 'result').randomSplit([0.8,0.2], seed=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaiveBayes(featuresCol = 'result', labelCol = log_df.columns[0],  modelType=\"gaussian\")\n",
    "NB_model = NB.fit(train_df)\n",
    "predictions = NB_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|class|              result|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|[-0.6811982262879...|[-8.9007451315644...|[1.0,2.4436754384...|       0.0|\n",
      "|    0|[-0.6442804962396...|[-7.3109603886818...|[0.99999999999999...|       0.0|\n",
      "|    0|[-0.5820461862853...|[-10.463172004258...|[1.0,1.5437837586...|       0.0|\n",
      "|    0|[-0.5557772426732...|[-0.4076377662523...|[0.99999999990504...|       0.0|\n",
      "|    0|[-0.5451446071267...|[1.25950925190698...|[0.99999999700923...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- naive bayes --\n",
      "------------------------------------------------------------------------\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1028\n",
      "           1       0.00      0.00      0.00       141\n",
      "\n",
      "    accuracy                           0.78      1169\n",
      "   macro avg       0.43      0.44      0.44      1169\n",
      "weighted avg       0.76      0.78      0.77      1169\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Confusion matrix\n",
      " [[908 120]\n",
      " [141   0]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RFpredictB = predictions[predictions.prediction==0].toPandas()\n",
    "RFpredictM = predictions[predictions.prediction==1].toPandas()\n",
    "\n",
    "result = pd.concat([RFpredictM,RFpredictB])\n",
    "true_labels=(test_df.select(\"class\")).toPandas()\n",
    "predicted_labels=result[\"prediction\"]\n",
    "\n",
    "print(\"-- naive bayes --\")\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Classification Report\\n\",classification_report(true_labels, predicted_labels))\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Confusion matrix\\n\",confusion_matrix(true_labels,predicted_labels),\"\\n\\n\")\n",
    "nbc=confusion_matrix(true_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrix, the first row is the true negative, the second row is the true positive, the third row is the false positive and the fourth row is the false negative.\n",
    "we can see that spam is not classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dc894006d5f0d29326bd81edd6f8b6ec5b8aee7b4e752badc33c56f6f5963e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('Pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
